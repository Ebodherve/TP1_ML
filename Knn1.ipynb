{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74cffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a011bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction lit les donnÃ©es des spam et ham dans les repertoires : \n",
    "# dataset/ham et dataset/spam\n",
    "def load_data():\n",
    "    print(\"Loading data...\")\n",
    "    ham_files_location = os.listdir(\"dataset/ham\")\n",
    "    spam_files_location = os.listdir(\"dataset/spam\")\n",
    "    data = []\n",
    "    for file_path in ham_files_location:\n",
    "        try :\n",
    "            f = open(\"dataset/ham/\" + file_path, \"r\")\n",
    "            text = str(f.read())\n",
    "            data.append([text, \"ham\"])\n",
    "        except:\n",
    "            pass\n",
    "    # Load spam email\n",
    "    for file_path in spam_files_location:\n",
    "        try:\n",
    "            f = open(\"dataset/spam/\" + file_path, \"r\")\n",
    "            text = str(f.read())\n",
    "            data.append([text, \"spam\"])\n",
    "        except:\n",
    "            pass\n",
    "    data = np.array(data)\n",
    "    print(\"flag 1: loaded data\")\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c810819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data: noise removal\n",
    "def preprocess_data(data):\n",
    "    print(\"Preprocessing data...\")\n",
    "    punc = string.punctuation\n",
    "    sw = stopwords.words('english')\n",
    "    # Punctuation list\n",
    "    # Stopwords list\n",
    "    for record in data:\n",
    "        # Remove common punctuation and symbols\n",
    "        for item in punc:\n",
    "            record[0] = record[0].replace(item, \"\")\n",
    "        # Lowercase all letters and remove stopwords\n",
    "        splittedWords = record[0].split()\n",
    "        newText = \"\"\n",
    "        for word in splittedWords:\n",
    "            if word not in sw:\n",
    "                word = word.lower()\n",
    "                newText = newText + \" \" + word\n",
    "        record[0] = newText\n",
    "    print(\"flag 2: preprocessed data\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982a2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    print(\"Splitting data...\")\n",
    "    features = data[:, 0]# array containing all email text bodies\n",
    "    labels = data[:, 1]\n",
    "    # array containing corresponding labels\n",
    "    print(labels)\n",
    "    training_data, test_data, training_labels, test_labels = train_test_split(features, labels, test_size = 0.27,\n",
    "                                                                              random_state = 42)\n",
    "    print(\"flag 3: splitted data\")\n",
    "    return training_data, test_data, training_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cfcb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(text):\n",
    "    wordCounts = dict()\n",
    "    for word in text.split():\n",
    "        if word in wordCounts:\n",
    "            wordCounts[word] += 1\n",
    "        else:\n",
    "            wordCounts[word] = 1\n",
    "    return wordCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a6e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
    "    total = 0\n",
    "    for word in test_WordCounts:\n",
    "        if word in test_WordCounts and word in training_WordCounts:\n",
    "            total += (test_WordCounts[word] -training_WordCounts[word])**2\n",
    "            del training_WordCounts[word]\n",
    "        else:\n",
    "            total += test_WordCounts[word]**2\n",
    "    for word in training_WordCounts:\n",
    "        total += training_WordCounts[word]**2\n",
    "    return total**0.5\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2bef7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(selected_Kvalues):\n",
    "    spam_count = 0\n",
    "    ham_count = 0\n",
    "    for value in selected_Kvalues:\n",
    "        if value[0] == \"spam\":\n",
    "            spam_count += 1\n",
    "        else:\n",
    "            ham_count += 1\n",
    "    if spam_count > ham_count:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fba2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn_classifier(training_data, training_labels, test_data, K,tsize):\n",
    "    print(\"Running KNN Classifier...\")\n",
    "    result = []\n",
    "    counter = 1\n",
    "    # word counts for training email\n",
    "    training_WordCounts = []\n",
    "    for training_text in training_data:\n",
    "        training_WordCounts.append(get_count(training_text))\n",
    "    for test_text in test_data:\n",
    "        similarity = [] # List of euclidean distances\n",
    "        test_WordCounts = get_count(test_text) # word counts for test email\n",
    "        # Getting euclidean difference\n",
    "        for index in range(len(training_data)):\n",
    "            euclidean_diff = euclidean_difference(test_WordCounts,\n",
    "                                                  training_WordCounts[index])\n",
    "            similarity.append([training_labels[index],\n",
    "                               euclidean_diff])\n",
    "        # Sort list in ascending order based on euclidean difference\n",
    "        similarity = sorted(similarity, key = lambda i:i[1])\n",
    "        # Select K nearest neighbour\n",
    "        selected_Kvalues = []\n",
    "        for i in range(K):\n",
    "            selected_Kvalues.append(similarity[i])\n",
    "        # Predicting the class of email\n",
    "        result.append(get_class(selected_Kvalues))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72af54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(K):\n",
    "    data = load_data()\n",
    "    data = preprocess_data(data)\n",
    "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
    "    tsize = len(test_data)\n",
    "    result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize)\n",
    "    accuracy = accuracy_score(test_labels[:tsize], result)\n",
    "    print(\"training data size\\t: \" + str(len(training_data)))\n",
    "    print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
    "    print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
    "    print(\"Samples tested\\t\\t: \" + str(tsize))\n",
    "    print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
    "    print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
    "    print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) * tsize)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "main(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a7bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c7e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273dab30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2152c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473c70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c820c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf174f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
